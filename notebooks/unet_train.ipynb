{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tqdm-4.65.0-py3.10.egg/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from spot_master.unet import data\n",
    "from spot_master.unet.model import UNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = Compose([\n",
    "    data.RandomHorizontalFlip(),\n",
    "    data.RandomRotation(),\n",
    "    data.ToTensorWrapper(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.FISHSpotsDataset(\n",
    "    meta_csv=\"meta_train.csv\", root_dir=\"../FISH_spots\", transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = data.FISHSpotsDataset(\n",
    "    meta_csv=\"meta_test.csv\", root_dir=\"../FISH_spots\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(1, 1, 4).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "writer = SummaryWriter(\"runs/fish_spots_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50, Batch: 1/269, Loss: 0.8230\n",
      "Epoch: 1/50, Batch: 11/269, Loss: 0.8177\n",
      "Epoch: 1/50, Batch: 21/269, Loss: 0.8171\n",
      "Epoch: 1/50, Batch: 31/269, Loss: 0.8166\n",
      "Epoch: 1/50, Batch: 41/269, Loss: 0.8160\n",
      "Epoch: 1/50, Batch: 51/269, Loss: 0.8155\n",
      "Epoch: 1/50, Batch: 61/269, Loss: 0.8149\n",
      "Epoch: 1/50, Batch: 71/269, Loss: 0.8144\n",
      "Epoch: 1/50, Batch: 81/269, Loss: 0.8138\n",
      "Epoch: 1/50, Batch: 91/269, Loss: 0.8133\n",
      "Epoch: 1/50, Batch: 101/269, Loss: 0.8127\n",
      "Epoch: 1/50, Batch: 111/269, Loss: 0.8121\n",
      "Epoch: 1/50, Batch: 121/269, Loss: 0.8116\n",
      "Epoch: 1/50, Batch: 131/269, Loss: 0.8110\n",
      "Epoch: 1/50, Batch: 141/269, Loss: 0.8105\n",
      "Epoch: 1/50, Batch: 151/269, Loss: 0.8099\n",
      "Epoch: 1/50, Batch: 161/269, Loss: 0.8094\n",
      "Epoch: 1/50, Batch: 171/269, Loss: 0.8088\n",
      "Epoch: 1/50, Batch: 181/269, Loss: 0.8083\n",
      "Epoch: 1/50, Batch: 191/269, Loss: 0.8077\n",
      "Epoch: 1/50, Batch: 201/269, Loss: 0.8072\n",
      "Epoch: 1/50, Batch: 211/269, Loss: 0.8066\n",
      "Epoch: 1/50, Batch: 221/269, Loss: 0.8061\n",
      "Epoch: 1/50, Batch: 231/269, Loss: 0.8055\n",
      "Epoch: 1/50, Batch: 241/269, Loss: 0.8050\n",
      "Epoch: 1/50, Batch: 251/269, Loss: 0.8044\n",
      "Epoch: 1/50, Batch: 261/269, Loss: 0.8039\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/wzxu/Projects/SpotMaster/notebooks/../spot_master/unet/data.py\", line 31, in __getitem__\n    image = io.imread(img_path)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/skimage/io/_io.py\", line 53, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 205, in call_plugin\n    return func(*args, **kwargs)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1062, in imread\n    with TiffFile(\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 3993, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 13929, in __init__\n    self.open()\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 13944, in open\n    self._fh = open(self._file, self._mode)  # type: ignore\nFileNotFoundError: [Errno 2] No such file or directory: '/home/wzxu/Projects/SpotMaster/notebooks/FISH_spots/image/RCA_717.tif'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m     31\u001b[0m         images \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     32\u001b[0m         masks \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n",
      "File \u001b[0;32m/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/wzxu/Projects/SpotMaster/notebooks/../spot_master/unet/data.py\", line 31, in __getitem__\n    image = io.imread(img_path)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/skimage/io/_io.py\", line 53, in imread\n    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/skimage/io/manage_plugins.py\", line 205, in call_plugin\n    return func(*args, **kwargs)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/skimage/io/_plugins/tifffile_plugin.py\", line 74, in imread\n    return tifffile_imread(fname, **kwargs)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 1062, in imread\n    with TiffFile(\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 3993, in __init__\n    fh = FileHandle(file, mode=mode, name=name, offset=offset, size=size)\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 13929, in __init__\n    self.open()\n  File \"/opt/anaconda/envs/cuda/lib/python3.10/site-packages/tifffile/tifffile.py\", line 13944, in open\n    self._fh = open(self._file, self._mode)  # type: ignore\nFileNotFoundError: [Errno 2] No such file or directory: '/home/wzxu/Projects/SpotMaster/notebooks/FISH_spots/image/RCA_717.tif'\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_epochs = 50\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        images = batch[\"image\"].to(device, dtype=torch.float)\n",
    "        masks = batch[\"mask\"].to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Epoch: {epoch + 1}/{num_epochs}, Batch: {idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"Loss/train_batch\", loss.item(), epoch * len(train_loader) + idx)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch[\"image\"].to(device, dtype=torch.float)\n",
    "            masks = batch[\"mask\"].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"Best model saved with Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
